"""
AFOLIE Image Size Nodes - å›¾åƒç¼©æ”¾èŠ‚ç‚¹
æä¾›åƒç´ å’Œå€æ•°ä¸¤ç§ç¼©æ”¾æ–¹å¼
"""

import torch
import numpy as np
from PIL import Image


def tensor2pil(image):
    """Convert tensor to PIL Image"""
    return Image.fromarray(np.clip(255. * image.cpu().numpy().squeeze(), 0, 255).astype(np.uint8))


def pil2tensor(image):
    """Convert PIL Image to tensor"""
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)


# é‡‡æ ·æ–¹æ³•åˆ—è¡¨ï¼ˆä¸¤ä¸ªèŠ‚ç‚¹å…±ç”¨ï¼‰
SAMPLING_METHODS = [
    "ä¸¤æ¬¡ç«‹æ–¹(å¹³æ»‘æ¸å˜)",
    "ä¿ç•™ç»†èŠ‚(æ‰©å¤§)",
    "ä¿ç•™ç»†èŠ‚2.0",
    "ä¸¤æ¬¡ç«‹æ–¹(è¾ƒå¹³æ»‘)(æ‰©å¤§)",
    "ä¸¤æ¬¡ç«‹æ–¹(è¾ƒé”åˆ©)(ç¼©å‡)",
    "é‚»è¿‘(ç¡¬è¾¹ç¼˜)",
    "ä¸¤æ¬¡çº¿æ€§"
]


class AFOLIEå›¾åƒåƒç´ ç¼©æ”¾:
    """
    å›¾åƒåƒç´ ç¼©æ”¾èŠ‚ç‚¹
    é€šè¿‡æŒ‡å®šå®½åº¦å’Œé«˜åº¦æ¥è°ƒæ•´å›¾åƒå¤§å°
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "å›¾åƒ": ("IMAGE",),
                "å®½åº¦": ("INT", {
                    "default": 512,
                    "min": 2,
                    "max": 2048,
                    "step": 1
                }),
                "é«˜åº¦": ("INT", {
                    "default": 512,
                    "min": 2,
                    "max": 2048,
                    "step": 1
                }),
                "é‡‡æ ·æ–¹æ³•": (SAMPLING_METHODS,),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "resize_image"
    CATEGORY = "AFOLIE/å›¾åƒ"

    def resize_image(self, å›¾åƒ, å®½åº¦, é«˜åº¦, é‡‡æ ·æ–¹æ³•):
        """
        ä½¿ç”¨åƒç´ å€¼è°ƒæ•´å›¾åƒå¤§å°
        
        Args:
            å›¾åƒ: è¾“å…¥å›¾åƒå¼ é‡
            å®½åº¦: ç›®æ ‡å®½åº¦ï¼ˆåƒç´ ï¼‰
            é«˜åº¦: ç›®æ ‡é«˜åº¦ï¼ˆåƒç´ ï¼‰
            é‡‡æ ·æ–¹æ³•: é‡æ–°é‡‡æ ·ç®—æ³•
        """
        batch_size = å›¾åƒ.shape[0]
        target_width = å®½åº¦
        target_height = é«˜åº¦
        
        # å¤„ç†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªå›¾åƒ
        resized_images = []
        
        for i in range(batch_size):
            img = å›¾åƒ[i]
            
            # è½¬æ¢ä¸ºPILè¿›è¡Œé«˜è´¨é‡é‡é‡‡æ ·
            pil_img = tensor2pil(img)
            
            # å°†é‡é‡‡æ ·æ–¹æ³•æ˜ å°„åˆ°PILæ»¤é•œ
            resample_map = {
                "ä¸¤æ¬¡ç«‹æ–¹(å¹³æ»‘æ¸å˜)": Image.BICUBIC,
                "ä¿ç•™ç»†èŠ‚(æ‰©å¤§)": Image.LANCZOS,
                "ä¿ç•™ç»†èŠ‚2.0": Image.LANCZOS,
                "ä¸¤æ¬¡ç«‹æ–¹(è¾ƒå¹³æ»‘)(æ‰©å¤§)": Image.BICUBIC,
                "ä¸¤æ¬¡ç«‹æ–¹(è¾ƒé”åˆ©)(ç¼©å‡)": Image.BICUBIC,
                "é‚»è¿‘(ç¡¬è¾¹ç¼˜)": Image.NEAREST,
                "ä¸¤æ¬¡çº¿æ€§": Image.BILINEAR
            }
            
            pil_filter = resample_map.get(é‡‡æ ·æ–¹æ³•, Image.BICUBIC)
            
            # ä½¿ç”¨PILè°ƒæ•´å¤§å°
            resized_pil = pil_img.resize((target_width, target_height), pil_filter)
            
            # è½¬æ¢å›å¼ é‡
            resized_tensor = pil2tensor(resized_pil)
            
            resized_images.append(resized_tensor)
        
        # å°†æ‰€æœ‰å›¾åƒå †å å›æ‰¹æ¬¡
        result = torch.cat(resized_images, dim=0)
        
        return (result,)


class AFOLIEå›¾åƒå€æ•°ç¼©æ”¾:
    """
    å›¾åƒå€æ•°ç¼©æ”¾èŠ‚ç‚¹
    é€šè¿‡å€æ•°æ¥è°ƒæ•´å›¾åƒå¤§å°
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "å›¾åƒ": ("IMAGE",),
                "å€æ•°": ("FLOAT", {
                    "default": 1.0,
                    "min": 0.01,
                    "max": 12.0,
                    "step": 0.01
                }),
                "é‡‡æ ·æ–¹æ³•": (SAMPLING_METHODS,),
            },
        }

    RETURN_TYPES = ("IMAGE",)
    FUNCTION = "resize_image"
    CATEGORY = "AFOLIE/å›¾åƒ"

    def resize_image(self, å›¾åƒ, å€æ•°, é‡‡æ ·æ–¹æ³•):
        """
        ä½¿ç”¨å€æ•°è°ƒæ•´å›¾åƒå¤§å°
        
        Args:
            å›¾åƒ: è¾“å…¥å›¾åƒå¼ é‡
            å€æ•°: ç¼©æ”¾å€æ•°
            é‡‡æ ·æ–¹æ³•: é‡æ–°é‡‡æ ·ç®—æ³•
        """
        batch_size, orig_height, orig_width, channels = å›¾åƒ.shape
        
        # æ ¹æ®å€æ•°è®¡ç®—ç›®æ ‡å°ºå¯¸
        target_width = int(orig_width * å€æ•°)
        target_height = int(orig_height * å€æ•°)
        
        # ç¡®ä¿å°ºå¯¸è‡³å°‘ä¸º1
        target_width = max(1, target_width)
        target_height = max(1, target_height)
        
        # å¤„ç†æ‰¹æ¬¡ä¸­çš„æ¯ä¸ªå›¾åƒ
        resized_images = []
        
        for i in range(batch_size):
            img = å›¾åƒ[i]
            
            # è½¬æ¢ä¸ºPILè¿›è¡Œé«˜è´¨é‡é‡é‡‡æ ·
            pil_img = tensor2pil(img)
            
            # å°†é‡é‡‡æ ·æ–¹æ³•æ˜ å°„åˆ°PILæ»¤é•œ
            resample_map = {
                "ä¸¤æ¬¡ç«‹æ–¹(å¹³æ»‘æ¸å˜)": Image.BICUBIC,
                "ä¿ç•™ç»†èŠ‚(æ‰©å¤§)": Image.LANCZOS,
                "ä¿ç•™ç»†èŠ‚2.0": Image.LANCZOS,
                "ä¸¤æ¬¡ç«‹æ–¹(è¾ƒå¹³æ»‘)(æ‰©å¤§)": Image.BICUBIC,
                "ä¸¤æ¬¡ç«‹æ–¹(è¾ƒé”åˆ©)(ç¼©å‡)": Image.BICUBIC,
                "é‚»è¿‘(ç¡¬è¾¹ç¼˜)": Image.NEAREST,
                "ä¸¤æ¬¡çº¿æ€§": Image.BILINEAR
            }
            
            pil_filter = resample_map.get(é‡‡æ ·æ–¹æ³•, Image.BICUBIC)
            
            # ä½¿ç”¨PILè°ƒæ•´å¤§å°
            resized_pil = pil_img.resize((target_width, target_height), pil_filter)
            
            # è½¬æ¢å›å¼ é‡
            resized_tensor = pil2tensor(resized_pil)
            
            resized_images.append(resized_tensor)
        
        # å°†æ‰€æœ‰å›¾åƒå †å å›æ‰¹æ¬¡
        result = torch.cat(resized_images, dim=0)
        
        return (result,)


# Node registration
NODE_CLASS_MAPPINGS = {
    "AFOLIEå›¾åƒåƒç´ ç¼©æ”¾": AFOLIEå›¾åƒåƒç´ ç¼©æ”¾,
    "AFOLIEå›¾åƒå€æ•°ç¼©æ”¾": AFOLIEå›¾åƒå€æ•°ç¼©æ”¾
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AFOLIEå›¾åƒåƒç´ ç¼©æ”¾": "å›¾åƒåƒç´ ç¼©æ”¾ ğŸ“",
    "AFOLIEå›¾åƒå€æ•°ç¼©æ”¾": "å›¾åƒå€æ•°ç¼©æ”¾ ğŸ”¢"
}
