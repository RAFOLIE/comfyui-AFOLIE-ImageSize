"""
AFOLIE èƒŒæ™¯é€æ˜åŒ–èŠ‚ç‚¹
å°†æŒ‡å®šé¢œè‰²çš„èƒŒæ™¯è½¬æ¢ä¸ºé€æ˜
"""

import torch
import numpy as np
from PIL import Image
from scipy import ndimage


def tensor2pil(image):
    """Convert tensor to PIL Image (RGB) - handles single image tensor (H, W, C)"""
    img_np = image.cpu().numpy()
    # ç¡®ä¿æ˜¯ 3D æ•°ç»„ (H, W, C)
    if img_np.ndim == 4:
        img_np = img_np.squeeze(0)
    img_np = np.clip(255. * img_np, 0, 255).astype(np.uint8)
    
    # æ ¹æ®é€šé“æ•°è¿”å›ä¸åŒæ¨¡å¼
    if img_np.shape[2] == 4:
        return Image.fromarray(img_np, mode='RGBA')
    elif img_np.shape[2] == 3:
        return Image.fromarray(img_np, mode='RGB')
    else:
        return Image.fromarray(img_np)


def pil2tensor(image):
    """Convert PIL Image to tensor (supports RGBA) - returns (1, H, W, C)"""
    return torch.from_numpy(np.array(image).astype(np.float32) / 255.0).unsqueeze(0)


def hex_to_rgb(hex_color):
    """
    å°†åå…­è¿›åˆ¶é¢œè‰²è½¬æ¢ä¸º RGB å…ƒç»„
    
    Args:
        hex_color: åå…­è¿›åˆ¶é¢œè‰²å­—ç¬¦ä¸²ï¼Œå¦‚ '#ffffff' æˆ– 'ffffff'
    
    Returns:
        (r, g, b) å…ƒç»„ï¼Œå€¼èŒƒå›´ 0-255
    """
    hex_color = hex_color.lstrip('#')
    if len(hex_color) != 6:
        raise ValueError(f"æ— æ•ˆçš„åå…­è¿›åˆ¶é¢œè‰²: {hex_color}")
    return tuple(int(hex_color[i:i+2], 16) for i in (0, 2, 4))


def color_distance(img_array, target_rgb):
    """
    è®¡ç®—å›¾åƒä¸­æ¯ä¸ªåƒç´ ä¸ç›®æ ‡é¢œè‰²çš„æ¬§å‡ é‡Œå¾—è·ç¦»
    
    Args:
        img_array: numpy æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (H, W, 3)ï¼Œå€¼èŒƒå›´ 0-255
        target_rgb: ç›®æ ‡é¢œè‰² (r, g, b)ï¼Œå€¼èŒƒå›´ 0-255
    
    Returns:
        è·ç¦»æ•°ç»„ï¼Œå½¢çŠ¶ä¸º (H, W)ï¼Œå€¼èŒƒå›´ 0-441.67ï¼ˆsqrt(255^2 * 3)ï¼‰
    """
    target = np.array(target_rgb, dtype=np.float32)
    diff = img_array.astype(np.float32) - target
    distance = np.sqrt(np.sum(diff ** 2, axis=2))
    return distance


def find_edge_connected_regions(mask):
    """
    æ‰¾åˆ°ä¸å›¾åƒè¾¹ç¼˜è¿é€šçš„åŒºåŸŸ
    
    Args:
        mask: å¸ƒå°”æ•°ç»„ï¼ŒTrue è¡¨ç¤ºåŒ¹é…ç›®æ ‡é¢œè‰²çš„åƒç´ 
    
    Returns:
        å¸ƒå°”æ•°ç»„ï¼ŒTrue è¡¨ç¤ºä¸è¾¹ç¼˜è¿é€šçš„åŒ¹é…åƒç´ 
    """
    h, w = mask.shape
    
    # åˆ›å»ºä¸€ä¸ªè¾¹ç¼˜ç§å­æ©ç 
    edge_seed = np.zeros_like(mask, dtype=bool)
    edge_seed[0, :] = mask[0, :]      # ä¸Šè¾¹ç¼˜
    edge_seed[-1, :] = mask[-1, :]    # ä¸‹è¾¹ç¼˜
    edge_seed[:, 0] = mask[:, 0]      # å·¦è¾¹ç¼˜
    edge_seed[:, -1] = mask[:, -1]    # å³è¾¹ç¼˜
    
    # ä½¿ç”¨æ ‡ç­¾è¿é€šåŒºåŸŸ
    labeled_array, num_features = ndimage.label(mask)
    
    # æ‰¾åˆ°ä¸è¾¹ç¼˜è¿é€šçš„æ ‡ç­¾
    edge_labels = set(labeled_array[edge_seed])
    edge_labels.discard(0)  # ç§»é™¤èƒŒæ™¯æ ‡ç­¾
    
    # åˆ›å»ºç»“æœæ©ç 
    edge_connected = np.zeros_like(mask, dtype=bool)
    for label in edge_labels:
        edge_connected |= (labeled_array == label)
    
    return edge_connected


class AFOLIEèƒŒæ™¯é€æ˜åŒ–:
    """
    èƒŒæ™¯é€æ˜åŒ–èŠ‚ç‚¹
    å°†æŒ‡å®šé¢œè‰²çš„èƒŒæ™¯è½¬æ¢ä¸ºé€æ˜
    """
    
    def __init__(self):
        pass
    
    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "å›¾åƒ": ("IMAGE",),
                "é€æ˜è‰²å€¼": ("STRING", {
                    "default": "#ffffff",
                    "multiline": False
                }),
                "é¢œè‰²å®¹å·®": ("FLOAT", {
                    "default": 10.0,
                    "min": 0.0,
                    "max": 100.0,
                    "step": 0.5,
                    "display": "slider"
                }),
                "ä¿æŠ¤ä¸»ä½“å†…éƒ¨é¢œè‰²": ("BOOLEAN", {
                    "default": True
                }),
            },
        }

    RETURN_TYPES = ("IMAGE", "MASK")
    RETURN_NAMES = ("å›¾åƒ", "é®ç½©")
    FUNCTION = "make_transparent"
    CATEGORY = "AFOLIE/å›¾åƒ"

    def make_transparent(self, å›¾åƒ, é€æ˜è‰²å€¼, é¢œè‰²å®¹å·®, ä¿æŠ¤ä¸»ä½“å†…éƒ¨é¢œè‰²):
        """
        å°†æŒ‡å®šé¢œè‰²çš„èƒŒæ™¯è½¬æ¢ä¸ºé€æ˜
        
        Args:
            å›¾åƒ: è¾“å…¥å›¾åƒå¼ é‡ (B, H, W, C)
            é€æ˜è‰²å€¼: åå…­è¿›åˆ¶é¢œè‰²å­—ç¬¦ä¸²ï¼Œå¦‚ '#ffffff'
            é¢œè‰²å®¹å·®: é¢œè‰²åŒ¹é…å®¹å·®ç™¾åˆ†æ¯” (0-100)
            ä¿æŠ¤ä¸»ä½“å†…éƒ¨é¢œè‰²: æ˜¯å¦ä¿æŠ¤ä¸»ä½“å†…éƒ¨çš„ç›¸ä¼¼é¢œè‰²
        
        Returns:
            (é€æ˜å›¾åƒ RGBA, é®ç½©)
        """
        # è§£æç›®æ ‡é¢œè‰²
        try:
            target_rgb = hex_to_rgb(é€æ˜è‰²å€¼)
        except ValueError:
            # å¦‚æœé¢œè‰²æ— æ•ˆï¼Œé»˜è®¤ä½¿ç”¨ç™½è‰²
            target_rgb = (255, 255, 255)
        
        batch_size = å›¾åƒ.shape[0]
        
        # è®¡ç®—é¢œè‰²è·ç¦»é˜ˆå€¼
        # æœ€å¤§è·ç¦»çº¦ä¸º 441.67 (sqrt(255^2 * 3))
        max_distance = np.sqrt(255**2 * 3)
        threshold = (é¢œè‰²å®¹å·® / 100.0) * max_distance
        
        result_images = []
        result_masks = []
        
        for i in range(batch_size):
            img = å›¾åƒ[i]
            
            # è½¬æ¢ä¸º PIL å›¾åƒ
            pil_img = tensor2pil(img)
            
            # è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œå€¼èŒƒå›´ 0-255
            img_array = np.array(pil_img)
            
            # ç¡®ä¿åªä½¿ç”¨ RGB é€šé“è¿›è¡Œé¢œè‰²è·ç¦»è®¡ç®—
            if img_array.ndim == 3 and img_array.shape[2] == 4:
                # RGBA å›¾åƒï¼Œåªå– RGB é€šé“
                rgb_array = img_array[:, :, :3]
            else:
                rgb_array = img_array
            
            # è®¡ç®—æ¯ä¸ªåƒç´ ä¸ç›®æ ‡é¢œè‰²çš„è·ç¦»
            distance = color_distance(rgb_array, target_rgb)
            
            # åˆ›å»ºåŒ¹é…æ©ç  (True = åŒ¹é…ç›®æ ‡é¢œè‰²ï¼Œéœ€è¦é€æ˜åŒ–)
            match_mask = distance <= threshold
            
            # å¦‚æœå¯ç”¨ä¿æŠ¤ä¸»ä½“å†…éƒ¨é¢œè‰²
            if ä¿æŠ¤ä¸»ä½“å†…éƒ¨é¢œè‰²:
                # åªé€æ˜åŒ–ä¸è¾¹ç¼˜è¿é€šçš„åŒºåŸŸ
                transparent_mask = find_edge_connected_regions(match_mask)
            else:
                transparent_mask = match_mask
            
            # åˆ›å»º RGBA å›¾åƒ
            rgba_array = np.zeros((rgb_array.shape[0], rgb_array.shape[1], 4), dtype=np.uint8)
            rgba_array[:, :, :3] = rgb_array  # RGB é€šé“ï¼ˆç¡®ä¿æ˜¯3é€šé“ï¼‰
            rgba_array[:, :, 3] = 255  # Alpha é€šé“é»˜è®¤ä¸é€æ˜
            rgba_array[transparent_mask, 3] = 0  # è®¾ç½®é€æ˜åŒºåŸŸçš„ alpha ä¸º 0
            
            # è½¬æ¢ä¸º PIL RGBA å›¾åƒï¼Œç„¶åè½¬ä¸ºå¼ é‡
            rgba_pil = Image.fromarray(rgba_array, mode='RGBA')
            rgba_tensor = pil2tensor(rgba_pil)  # (1, H, W, 4)
            result_images.append(rgba_tensor)
            
            # åˆ›å»ºé®ç½© - ä» alpha é€šé“æå–
            # alpha=255 -> 1.0 (å‰æ™¯/ä¸»ä½“), alpha=0 -> 0.0 (èƒŒæ™¯/é€æ˜)
            mask_array = (~transparent_mask).astype(np.float32)
            mask_tensor = torch.from_numpy(mask_array).unsqueeze(0)
            result_masks.append(mask_tensor)
        
        # åˆå¹¶æ‰¹æ¬¡
        final_image = torch.cat(result_images, dim=0)  # (B, H, W, 4)
        final_mask = torch.cat(result_masks, dim=0)    # (B, H, W)
        
        return (final_image, final_mask)


# Node registration
NODE_CLASS_MAPPINGS = {
    "AFOLIEèƒŒæ™¯é€æ˜åŒ–": AFOLIEèƒŒæ™¯é€æ˜åŒ–
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "AFOLIEèƒŒæ™¯é€æ˜åŒ–": "èƒŒæ™¯é€æ˜åŒ– ğŸ¨"
}
